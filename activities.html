<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Activities – Intelligent Agents e-Portfolio</title>
  <link rel="stylesheet" href="style.css" />
</head>

<body id="top">
  <a class="skip-link" href="#main">Skip to content</a>

  <header class="site-header">
    <div class="header-inner">
      <div class="brand">
        <h1>Intelligent Agents</h1>
        <div class="sub">MSc Artificial Intelligence – e-Portfolio</div>
      </div>

<nav class="main-nav">
  <ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="discussion.html">Discussions</a></li>
    <li><a href="research.html">Research &amp; Proposal</a></li>
    <li><a href="statistics.html">Statistics &amp; Data</a></li>
    <li><a href="reflections.html">Reflections</a></li>
    <li><a class="active" href="activities.html" aria-current="page">Activities</a></li>
    <li><a href="about.html">About</a></li>
  </ul>
</nav>


    </div>
  </header>

  <main id="main" class="container">
<section class="hero">
  <h2>Activities</h2>
  <p>
    This page presents my key learning activities and practical artefacts completed during the Intelligent Agents module,
    including exercises, system design work, and implementation-related evidence. Each activity summarises the aim, what I did,
    the artefacts produced (e.g., design documentation, presentations, and supporting materials), and the learning outcome, with
    links to relevant evidence where applicable.
  </p>
  <div class="meta">
    <span class="badge">Exercises + artefacts</span>
    <span class="badge">Design + implementation evidence</span>
    <span class="badge">Method + outcome</span>
  </div>
</section>


    <section class="grid">

      <div class="card prose">
        <h3>Activity 1: Agent Concepts and Architectures</h3>
        <p class="muted">
          Focus: what an intelligent agent is, how it perceives the environment, and how different architectures
          (reactive, deliberative, hybrid, and BDI) impact behaviour.
        </p>

        <details open>
          <summary>
            <span>What I did</span>
            <span class="summary-right">Evidence + learning</span>
          </summary>
          <div class="detail-body">
            <ul>
              <li>Reviewed core definitions of intelligent agents and agent environments (fully/partially observable, deterministic/stochastic, episodic/sequential).</li>
              <li>Compared reactive, deliberative, hybrid, and BDI architectures and mapped each to suitable real-world contexts.</li>
              <li>Linked architectures to organisational settings where autonomy, resilience, and distributed decision-making are important.</li>
            </ul>

            <div class="kv">
              <div>Evidence</div>
              <div>Structured comparison notes + architecture-to-context mapping (included in my reflections and discussions).</div>
              <div>Outcome</div>
              <div>Clear understanding of when to use each architecture and how agent design choices affect reliability, explainability, and performance.</div>
            </div>

            <div class="refs">
              <h4>References</h4>
              <ul>
                <li>Russell, S. and Norvig, P. (2021) <em>Artificial Intelligence: A Modern Approach</em>. 4th edn. Harlow: Pearson.</li>
                <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
                <li>Rao, A.S. and Georgeff, M.P. (1995) ‘BDI agents: From theory to practice’, in <em>ICMAS 1995</em>, pp. 312–319.</li>
              </ul>
            </div>
          </div>
        </details>
      </div>

      <div class="card prose">
        <h3>Activity 2: Multi-Agent Coordination and Emergent Behaviour</h3>
        <p class="muted">
          Focus: how agents coordinate, why decentralised systems generate emergent outcomes, and why governance matters
          for safety and accountability.
        </p>

        <details open>
          <summary>
            <span>What I did</span>
            <span class="summary-right">Evidence + learning</span>
          </summary>
          <div class="detail-body">
            <ul>
              <li>Explored how coordination can be achieved through communication, negotiation, shared goals, and protocols.</li>
              <li>Studied emergent behaviour and why local decision-making may produce unexpected global patterns.</li>
              <li>Connected these risks to governance needs in real organisations (monitoring, constraints, escalation, and auditability).</li>
            </ul>

            <div class="kv">
              <div>Evidence</div>
              <div>Discussion 1 (case examples + governance risk analysis) and structured summary post.</div>
              <div>Outcome</div>
              <div>Improved ability to evaluate agent-based systems not only technically but also as socio-technical systems needing oversight.</div>
            </div>

            <div class="refs">
              <h4>References</h4>
              <ul>
                <li>Macal, C.M. and North, M.J. (2010) ‘Tutorial on agent-based modelling and simulation’, <em>Journal of Simulation</em>, 4(3), pp. 151–162.</li>
                <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence</em>. Cham: Springer.</li>
                <li>Rahwan, I. (2018) ‘Society-in-the-loop: Programming the algorithmic social contract’, <em>Ethics and Information Technology</em>, 20(1), pp. 5–14.</li>
              </ul>
            </div>
          </div>
        </details>
      </div>

      <div class="card prose">
        <h3>Activity 3: Agent Communication and ACLs (KQML / FIPA-ACL)</h3>
        <p class="muted">
          Focus: why agent communication differs from method invocation, how performatives represent intent,
          and what risks arise from semantics and ontology mismatch.
        </p>

        <details open>
          <summary>
            <span>What I did</span>
            <span class="summary-right">Evidence + learning</span>
          </summary>
          <div class="detail-body">
            <ul>
              <li>Analysed KQML concepts and the purpose of performatives (ask, tell, achieve) for goal-driven coordination.</li>
              <li>Compared ACLs with Java/Python method invocation (coupling, predictability, overhead, and scalability).</li>
              <li>Identified the role of shared ontologies and protocols in reducing ambiguity in open multi-agent environments.</li>
            </ul>

            <div class="kv">
              <div>Evidence</div>
              <div>Discussion 2 initial post, peer responses, and summary post with references.</div>
              <div>Outcome</div>
              <div>Clear understanding of when ACLs are essential (open systems) and when method calls are better (closed, tightly controlled systems).</div>
            </div>

            <div class="refs">
              <h4>References</h4>
              <ul>
                <li>Finin, T., Fritzson, R., McKay, D. and McEntire, R. (1994) ‘KQML as an agent communication language’, in <em>CIKM</em>. New York: ACM, pp. 456–463.</li>
                <li>Gruber, T. (1993) ‘A translation approach to portable ontology specifications’, <em>Knowledge Acquisition</em>, 5(2), pp. 199–220.</li>
                <li>Weiss, G. (1999) <em>Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence</em>. Cambridge, MA: MIT Press.</li>
              </ul>
            </div>
          </div>
        </details>
      </div>

      <div class="card prose">
        <h3>Activity 4: Ethics and Risk in Generative / Autonomous Systems</h3>
        <p class="muted">
          Focus: ethical risks (bias, misinformation, IP, accountability) and how governance + technical safeguards reduce harm
          when deploying AI agents in real settings.
        </p>

        <details open>
          <summary>
            <span>What I did</span>
            <span class="summary-right">Evidence + learning</span>
          </summary>
          <div class="detail-body">
            <ul>
              <li>Reviewed ethical issues in deep learning–enabled generative technologies and mapped risks to real-world consequences.</li>
              <li>Examined prevention strategies: auditing, transparency, provenance, human oversight, and responsible deployment policies.</li>
              <li>Connected ethical evaluation to professional responsibility and decision-making in organisational environments.</li>
            </ul>

            <div class="kv">
              <div>Evidence</div>
              <div>Discussion 3 initial post, peer responses, and summary post (Units 9–11 coverage).</div>
              <div>Outcome</div>
              <div>Ability to assess an AI/agent system beyond performance: considering fairness, safety, compliance, and accountability.</div>
            </div>

            <div class="refs">
              <h4>References</h4>
              <ul>
                <li>Floridi, L. et al. (2018) ‘AI4People—An ethical framework for a good AI society’, <em>Minds and Machines</em>, 28(4), pp. 689–707.</li>
                <li>Chesney, R. and Citron, D. (2019) ‘Deepfakes: A looming challenge…’, <em>California Law Review</em>, 107(6), pp. 1753–1820.</li>
                <li>Jobin, A., Ienca, M. and Vayena, E. (2019) ‘The global landscape of AI ethics guidelines’, <em>Nature Machine Intelligence</em>, 1(9), pp. 389–399.</li>
              </ul>
            </div>
          </div>
        </details>
      </div>

      <div class="card prose">
        <h3>Activity 5: Applying Intelligent Agents to My Professional Context</h3>
        <p class="muted">
          Focus: translating module concepts into a realistic organisational context (healthcare / operations),
          identifying what an agent system could do, and what constraints would be required.
        </p>

        <details open>
          <summary>
            <span>What I did</span>
            <span class="summary-right">Evidence + learning</span>
          </summary>
          <div class="detail-body">
            <ul>
              <li>Outlined realistic tasks that an agent system could support in complex service environments (monitoring, coordination, prioritisation, and escalation).</li>
              <li>Identified boundaries required for safe deployment: data governance, audit logs, human oversight, and operational constraints.</li>
              <li>Reflected on how intelligent agents support decision-making under uncertainty without removing accountability.</li>
            </ul>

            <div class="kv">
              <div>Evidence</div>
              <div>Reflection notes and integration across discussion summaries (governance + ethics + architecture).</div>
              <div>Outcome</div>
              <div>Improved ability to argue for (or against) agent deployment based on context, not hype, including risks and safeguards.</div>
            </div>

            <div class="refs">
              <h4>References</h4>
              <ul>
                <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
                <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence</em>. Cham: Springer.</li>
              </ul>
            </div>
          </div>
        </details>
      </div>
<div class="card prose">
  <h3>Activity 6: Creating Agent Dialogues (KQML + KIF)</h3>
  <p class="muted">
    Focus: constructing a structured agent dialogue using KQML performatives and KIF-style content to support
    autonomous communication between agents in a distributed system.
  </p>

  <details open>
    <summary>
      <span>What I did</span>
      <span class="summary-right">Evidence + learning</span>
    </summary>

    <div class="detail-body">
      <ul>
        <li>Designed a KQML-based dialogue between two agents: Alice (procurement agent) and Bob (warehouse stock agent).</li>
        <li>Used KQML performatives (<code>ask-one</code>, <code>tell</code>) to express communicative intent.</li>
        <li>Represented message content using KIF-style logical expressions and variables.</li>
        <li>Applied a shared ontology to reduce semantic ambiguity between agents.</li>
      </ul>

      <h4>Agent Dialogue</h4>

      <pre><code>(ask-one
  :sender Alice
  :receiver Bob
  :language KIF
  :ontology Warehouse-Stock
  :content (available-stock (item "Television") (size-inches 50) ?qty))</code></pre>

      <pre><code>(tell
  :sender Bob
  :receiver Alice
  :language KIF
  :ontology Warehouse-Stock
  :content (= ?qty 18))</code></pre>

      <pre><code>(ask-one
  :sender Alice
  :receiver Bob
  :language KIF
  :ontology Warehouse-Stock
  :content (hdmi-slots (item "Television") (size-inches 50) ?ports))</code></pre>

      <pre><code>(tell
  :sender Bob
  :receiver Alice
  :language KIF
  :ontology Warehouse-Stock
  :content (= ?ports 3))</code></pre>

      <div class="kv">
        <div>Evidence</div>
        <div>
          Complete KQML/KIF dialogue demonstrating agent communication, intent separation, and ontology-based reasoning.
        </div>

        <div>Outcome</div>
        <div>
          Practical understanding of how agent communication languages enable autonomous, knowledge-level interaction
          beyond simple method invocation.
        </div>
      </div>

      <div class="refs">
        <h4>References</h4>
        <ul>
          <li>Finin, T. et al. (1994) ‘KQML as an agent communication language’, in <em>CIKM</em>. New York: ACM.</li>
          <li>Gruber, T. (1993) ‘A translation approach to portable ontology specifications’, <em>Knowledge Acquisition</em>, 5(2), pp. 199–220.</li>
          <li>Weiss, G. (1999) <em>Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence</em>. Cambridge, MA: MIT Press.</li>
        </ul>
      </div>
    </div>
  </details>
</div>

      
<div class="card prose">
  <h3>Activity 7: Individual Development Project (Post–Team Project)</h3>
  <p class="muted">
    Focus: translating the Unit 6 team design into an individual, practical implementation and communicating design
    decisions through a structured technical presentation.
  </p>

  <details open>
    <summary>
      <span>What I did</span>
      <span class="summary-right">Evidence + learning</span>
    </summary>

    <div class="detail-body">
      <ul>
        <li>Implemented a simplified multi-agent pipeline based on the Unit 6 digital forensics design, focusing on modular agent roles.</li>
        <li>Applied core agent concepts such as task decomposition, controlled communication, and auditability.</li>
        <li>Produced a narrated individual presentation explaining the system design, trade-offs, and future extensions.</li>
        <li>Critically evaluated why transparency and determinism were prioritised over complex inter-agent communication in this context.</li>
      </ul>

      <div class="kv">
        <div>Evidence</div>
        <div>
          Individual project presentation and transcript, implementation documentation, and supporting artefacts
          (see linked assets).
        </div>

        <div>Outcome</div>
        <div>
          Improved ability to move from conceptual agent design to defensible implementation, and to justify
          architectural choices in relation to domain constraints and ethical requirements.
        </div>
      </div>

      <div class="refs">
        <h4>References</h4>
        <ul>
          <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
          <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence</em>. Cham: Springer.</li>
        </ul>
      </div>
    </div>
  </details>
</div>

    </section>

    <footer class="footer">
      <span>© Naeema Alnaqbi • Intelligent Agents e-Portfolio</span>
      <a class="toplink" href="#top">Back to top</a>
    </footer>
  </main>
</body>
</html>
