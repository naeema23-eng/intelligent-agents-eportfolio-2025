<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Collaborative Discussion 1 – Agent-Based Systems</title>
</head>
<body>

<h1>Intelligent Agents</h1>
<p>MSc Artificial Intelligence – e-Portfolio</p>

<ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="discussions.html">Discussions</a></li>
    <li><a href="activities.html">Activities</a></li>
    <li><a href="project.html">Project & Deep Learning</a></li>
    <li><a href="reflections.html">Reflections</a></li>
    <li><a href="about.html">About</a></li>
</ul>

<hr>

<h2>Collaborative Discussion 1: Agent-Based Systems (Units 1–3)</h2>

<p>This page includes my Initial Post, Peer Responses, and Summary Post for Collaborative Discussion 1.</p>

<hr>

<h3>Initial Post: The Rise and Benefits of Agent-Based Systems in Modern Organisations</h3>

<p>
The rise of agent-based systems (ABS) reflects a shift from centralised architectures toward
decentralised, adaptive intelligence that can cope with the complexity of modern organisations.
Traditional systems struggle when environments are distributed, dynamic and heterogeneous, whereas
ABS model such settings as collections of autonomous agents that perceive, reason and act locally
while still contributing to global organisational goals (Wooldridge and Jennings, 1995; Wooldridge, 2021).
Advances in artificial intelligence, especially in knowledge representation and learning, combined
with the growth of distributed computing, have made these systems feasible at scale
(Russell and Norvig, 2021; Macal and North, 2010).
</p>

<p>
From a technical perspective, several agent models support different organisational needs.
Logic-based Belief–Desire–Intention (BDI) agents link first-order logic and practical reasoning to
operational decision-making in complex domains (Rao and Georgeff, 1995). Behaviour-based agents,
inspired by Brooks’ “intelligence without representation”, provide fast, reactive control in robotics and
embedded systems (Brooks, 1991). Modern hybrid architectures combine deliberative and reactive
layers, while multi-agent reinforcement learning extends agents with adaptive behaviour in cooperative
and competitive environments (Lowe et al., 2017; Winikoff, 2017).
</p>

<p>
The organisational benefits of ABS are visible in several real-world systems. In manufacturing,
DaimlerChrysler’s agent-based control improved robustness and flexibility on production lines operating
under uncertainty (Jennings and Bussmann, 2003). In logistics, Kiva Systems (now Amazon Robotics)
used hundreds of warehouse robots coordinated through an agent-based approach to double picker
productivity and increase throughput (Wurman, D’Andrea and Mountz, 2008). At infrastructure level,
the JADE framework provides a FIPA-compliant platform that allows organisations to deploy interoperable
agents for coordination, negotiation and distributed control (Bellifemine, Caire and Greenwood, 2007).
Recent multi-agent reinforcement learning work, such as DeepMind-style actor–critic methods,
demonstrates how agents can jointly learn strategies for complex tasks, pointing to future applications
in markets, traffic and resource allocation (Lowe et al., 2017).
</p>

<p>
However, these benefits come with non-trivial risks. Autonomous agents can produce emergent behaviours
that conflict with organisational policies or legal requirements if they are not properly governed
(Dignum, 2019; Rahwan, 2018). In data-driven agents, privacy and compliance with frameworks such as
the EU General Data Protection Regulation (GDPR) must be considered when agents share or process
personal data across distributed environments (Voigt and Von dem Bussche, 2017). This makes accountability,
formal verification and transparent decision-making essential (Fisher et al., 2021; Raji et al., 2020).
</p>

<p>
Overall, agent-based systems are well aligned with organisations that operate in distributed, uncertain
and fast-changing contexts. When combined with clear governance, human oversight and legal safeguards,
they offer a powerful way to scale decision-making, improve resilience and manage complexity.
</p>

<h4>References (Initial Post)</h4>

<p>
Bellifemine, F., Caire, G. and Greenwood, D. (2007) <i>Developing Multi-Agent Systems with JADE</i>.
Chichester: John Wiley & Sons.<br>
Brooks, R.A. (1991) ‘Intelligence without representation’, <i>Artificial Intelligence</i>, 47(1–3), pp. 139–159.<br>
Dignum, V. (2019) <i>Responsible Artificial Intelligence</i>. Cham: Springer.<br>
Fisher, M. et al. (2021) ‘Towards a framework for certification of reliable autonomous systems’,
<i>Autonomous Agents and Multi-Agent Systems</i>, 35(1), pp. 1–65.<br>
Jennings, N.R. and Bussmann, S. (2003) ‘Agent-based control systems’, <i>IEEE Control Systems Magazine</i>,
23(3), pp. 61–73.<br>
Lowe, R. et al. (2017) ‘Multi-agent actor-critic for mixed cooperative–competitive environments’,
<i>NeurIPS 2017</i>, pp. 6379–6390.<br>
Macal, C.M. and North, M.J. (2010) ‘Tutorial on agent-based modelling and simulation’,
<i>Journal of Simulation</i>, 4(3), pp. 151–162.<br>
Raji, I.D. et al. (2020) ‘Closing the AI accountability gap’, <i>FAccT 2020</i>, pp. 336–345.<br>
Rao, A.S. and Georgeff, M.P. (1995) ‘BDI agents: From theory to practice’, <i>ICMAS 1995</i>, pp. 312–319.<br>
Rahwan, I. (2018) ‘Society-in-the-loop’, <i>Ethics and Information Technology</i>, 20(1), pp. 5–14.<br>
Russell, S. and Norvig, P. (2021) <i>Artificial Intelligence: A Modern Approach</i>.<br>
Voigt, P. and Von dem Bussche, A. (2017) <i>The EU GDPR: A Practical Guide</i>.<br>
Winikoff, M. (2017) ‘Challenges for engineering multi-agent systems’, <i>AAMAS</i>, 31(4), pp. 779–817.<br>
Wooldridge, M. (2021) <i>An Introduction to MultiAgent Systems</i>.<br>
Wooldridge, M. and Jennings, N.R. (1995) ‘Intelligent agents’, <i>The Knowledge Engineering Review</i>,
10(2), pp. 115–152.<br>
Wurman, P.R., D’Andrea, R. and Mountz, M. (2008) ‘Coordinating hundreds of cooperative robots’,
<i>AI Magazine</i>, 29(1), pp. 9–19.
</p>

<hr>

<h3>Peer Response: Ariel Mella</h3>

<p>
Hi Ariel,<br><br>
Your post offers a rich, historically grounded view of how agent-based systems (ABS) emerged from
centralised ERP-style architectures to today’s microservices, cloud and service-oriented designs.
I especially liked how you connected FIPA-compliant platforms with concrete industrial cases such
as DaimlerChrysler, Kiva and Alibaba, which clearly demonstrate that ABS deliver measurable value
rather than remaining only theoretical (Bellifemine, Poggi and Rimassa, 2001; Jennings and Bussmann,
2003; Wurman, D’Andrea and Mountz, 2008).
</p>

<p>
I agree with your emphasis on scalability and resilience, but I see your examples also highlighting a
second layer of value: learning and coordination under uncertainty. Your reference to MADDPG aligns
well with current work in multi-agent reinforcement learning, where centralised training with
decentralised execution helps agents learn stable joint policies in non-stationary environments
(Lowe et al., 2017). This addresses some of the “credit assignment” and coordination problems you
mentioned and connects directly to industrial settings such as traffic optimisation, RTB markets and
large-scale logistics (Foerster et al., 2018).
</p>

<p>
At the same time, your discussion of technical debt and process misalignment is crucial.
Sculley et al. (2015) showed that simply “dropping in” learning agents into legacy workflows can
create fragile systems that are hard to monitor and debug. Dignum (2019) and Rahwan (2018) argue
that such systems require explicit governance frameworks that make responsibilities and oversight
clear. I would add that, when ABS operate on personal or behavioural data, GDPR imposes strict
requirements on logging, sharing and retention (Voigt and Von dem Bussche, 2017).
</p>

<p>
Overall, your post helped me see ABS less as isolated technical components and more as
socio-technical systems shaped by processes, regulations and organisational culture.
</p>

<h4>References (Peer Response to Ariel)</h4>

<p>
Bellifemine, F., Poggi, A. and Rimassa, G. (2001) ‘Developing multi agent systems with a FIPA compliant
agent framework’, <i>Software: Practice and Experience</i>, 31(2), pp. 103–128.<br>
Dignum, V. (2019) <i>Responsible Artificial Intelligence</i>.<br>
Foerster, J.N. et al. (2018) ‘Counterfactual multi-agent policy gradients’, <i>AAAI</i>.<br>
Jennings, N.R. and Bussmann, S. (2003).<br>
Lowe, R. et al. (2017).<br>
Rahwan, I. (2018).<br>
Sculley, D. et al. (2015).<br>
Voigt, P. and Von dem Bussche, A. (2017).<br>
Wurman, P.R. et al. (2008).
</p>

<hr>

<h3>Peer Response: Bashair Alhosani</h3>

<p>
Hi Bashair,<br><br>
Your post gives a clear and well-structured explanation of how agent-based systems (ABS) emerged
from the limitations of centralised architectures and why they are attractive for modern organisations.
I particularly appreciated your use of the BDI model and the way you linked it back to AI foundations,
showing how beliefs, desires and intentions support practical decision-making (Rao and Georgeff,
1995; Russell and Norvig, 2021).
</p>

<p>
Building on your discussion of modularity and responsiveness, I highlighted that flexible and adaptive
agents also require strong governance and verification. Winikoff (2017) and Fisher et al. (2021)
emphasise the need for certification frameworks, especially when ABS support safety-critical decisions.
</p>

<p>
I also reinforced your point about hybrid architectures. In practice, many real-world systems combine
reactive agents for low-latency responses with deliberative or learning-based components for planning
and coordination (Wooldridge, 2021; Bellifemine, Caire and Greenwood, 2007). Kiva’s warehouse robots
are a strong example of this layered approach (Wurman, D’Andrea and Mountz, 2008).
</p>

<p>
Finally, I connected your discussion to legal and ethical dimensions. ABS that process personal or
behavioural data must comply with GDPR, which affects how data can be shared, logged and retained
(Voigt and Von dem Bussche, 2017). Dignum (2019) and Rahwan (2018) argue that ABS should sit within
responsible-AI governance structures.
</p>

<h4>References (Peer Response to Bashair)</h4>

<p>
Bellifemine, F., Caire, G. and Greenwood, D. (2007).<br>
Dignum, V. (2019).<br>
Fisher, M. et al. (2021).<br>
Rao, A.S. and Georgeff, M.P. (1995).<br>
Rahwan, I. (2018).<br>
Russell, S. and Norvig, P. (2021).<br>
Voigt, P. and Von dem Bussche, A. (2017).<br>
Winikoff, M. (2017).<br>
Wooldridge, M. (2021).<br>
Wurman, P.R. et al. (2008).
</p>

<hr>

<h3>Summary Post: Agent-Based Systems and Decentralised Intelligence</h3>

<p>
Across this discussion, my understanding of agent-based systems (ABS) evolved from viewing them as
a technical alternative to centralised systems to recognising them as a broader socio-technical
approach to managing complexity. Units 1–3 introduced core concepts such as intelligent agents,
agent architectures and logical representations, while peer contributions illustrated how these ideas
apply in logistics, healthcare, manufacturing and finance (Wooldridge and Jennings, 1995; Macal and
North, 2010; Wooldridge, 2021).
</p>

<p>
A key theme was that ABS excel in complex, distributed and dynamic environments. Agent-based
simulation enables organisations to explore “what-if” scenarios and emergent behaviours before
changing operations (Macal and North, 2010). Real-world deployments such as DaimlerChrysler’s
production lines and Kiva’s warehouse robots show how distributed agents increase robustness and
adaptability (Jennings and Bussmann, 2003; Wurman, D’Andrea and Mountz, 2008). JADE and FIPA
frameworks provide practical infrastructure for interoperable multi-agent systems (Bellifemine, Poggi
and Rimassa, 2001; Bellifemine, Caire and Greenwood, 2007).
</p>

<p>
The architectural models introduced—BDI, reactive, hybrid—helped me understand how agents link
knowledge, reasoning and action. Peers expanded this by highlighting multi-agent reinforcement
learning methods, where agents learn coordinated behaviours under centralised training but act
independently at runtime (Lowe et al., 2017; Foerster et al., 2018).
</p>

<p>
However, several risks and governance concerns emerged. Autonomous agents may produce harmful or
misaligned behaviours if goals diverge from organisational or societal values (Dignum, 2019; Rahwan,
2018). Responsible-AI frameworks emphasise accountability, transparency and auditability (Raji, Smart
and White, 2020). Formal verification and certification can help build trust in safety-critical systems
(Fisher et al., 2021; Winikoff, 2017). Legal considerations are also crucial, as systems that process
personal data must comply with GDPR (Voigt and Von dem Bussche, 2017).
</p>

<p>
Overall, this discussion helped me integrate theory, practical applications and critical reflection.
ABS appear most valuable when organisations combine decentralised autonomy with:
</p>

<ul>
    <li>clear representations of goals and knowledge,</li>
    <li>processes redesigned for autonomy,</li>
    <li>human oversight and escalation paths,</li>
    <li>strong ethical, legal and verification frameworks.</li>
</ul>

<p>
When these conditions are met, agent-based systems provide a powerful, future-oriented approach to
operating in complex digital environments.
</p>

<h4>References (Summary Post)</h4>

<p>
Bellifemine, F., Caire, G. and Greenwood, D. (2007).<br>
Bellifemine, F., Poggi, A. and Rimassa, G. (2001).<br>
Brooks, R.A. (1991).<br>
Dignum, V. (2019).<br>
Fisher, M. et al. (2021).<br>
Foerster, J.N. et al. (2018).<br>
Jennings, N.R. and Bussmann, S. (2003).<br>
Lowe, R. et al. (2017).<br>
Macal, C.M. and North, M.J. (2010).<br>
Raji, I.D. et al. (2020).<br>
Rao, A.S. and Georgeff, M.P. (1995).<br>
Rahwan, I. (2018).<br>
Russell, S. and Norvig, P. (2021).<br>
Voigt, P. and Von dem Bussche, A. (2017).<br>
Winikoff, M. (2017).<br>
Wooldridge, M. (2021).<br>
Wooldridge, M. and Jennings, N.R. (1995).<br>
Wurman, P.R., D’Andrea, R. and Mountz, M. (2008).
</p>

<hr>

<p>Collaborative Discussion 1 · Intelligent Agents e-Portfolio · Naeema Abdalla Ahmed Alnaqbi</p>

</body>
</html>
