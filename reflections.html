<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Reflections – Intelligent Agents e-Portfolio</title>
  <link rel="stylesheet" href="style.css" />
</head>

<body id="top">
  <a class="skip-link" href="#main">Skip to content</a>

  <header class="site-header">
    <div class="header-inner">
      <div class="brand">
        <h1>Intelligent Agents</h1>
        <div class="sub">MSc Artificial Intelligence – e-Portfolio</div>
      </div>

      <nav class="nav" aria-label="Main navigation">
        <a href="index.html">Home</a>
        <a href="discussion.html">Discussions</a>
        <a href="activities.html">Activities</a>
        <a href="statistics.html">Statistics</a>
        <a class="active" href="reflections.html" aria-current="page">Reflections</a>
        <a href="about.html">About</a>
      </nav>
    </div>
  </header>

  <main id="main" class="container">

    <section class="hero">
      <h2>Final Reflective Account</h2>
      <p>
        This reflective account evaluates my learning, contributions, and professional development throughout the
        Intelligent Agents module. The reflection follows the
        <strong>Rolfe et al. (2001)</strong> model: <em>What? – So What? – Now What?</em>
      </p>
      <div class="meta">
        <span class="badge">Reflection</span>
        <span class="badge">Critical analysis</span>
        <span class="badge">Professional development</span>
      </div>
    </section>

    <section class="grid">

      <div class="card prose">
        <h3>What? — Learning context and activities</h3>

        <p>
          The Intelligent Agents module introduced the theoretical foundations, practical techniques, and ethical
          implications of agent-based and multi-agent systems. Across Units 1–12, I engaged with a range of learning
          activities including collaborative discussions, critical peer responses, structured reading, and applied
          reasoning tasks.
        </p>

        <p>
          Key topics included agent architectures (reactive, deliberative, hybrid, and BDI), coordination and
          communication in multi-agent systems, agent communication languages (KQML and FIPA-ACL), and the integration
          of learning-based and generative models into agentic systems. These themes were explored through three
          collaborative discussions, each requiring an initial post, peer responses, and a final summary post.
        </p>

        <p>
          In parallel, module activities required me to consider how intelligent agents operate under uncertainty,
          how their performance can be evaluated quantitatively, and how ethical risks such as bias, misinformation,
          and accountability emerge when agents are deployed at scale. Together, these tasks formed a coherent
          learning journey that combined theory, application, and reflection.
        </p>
      </div>

      <div class="card prose">
        <h3>So What? — Analysis, emotions, and critical learning</h3>

        <p>
          At the start of the module, I primarily viewed intelligent agents as technical artefacts designed to optimise
          performance in distributed systems. My initial focus was on architectures, coordination mechanisms, and
          efficiency gains. However, engagement with peer discussions and contemporary literature significantly
          reshaped this perspective.
        </p>

        <p>
          Discussion 1 highlighted that agent-based systems are inherently <em>socio-technical</em>. While decentralised
          autonomy improves scalability and resilience, it also introduces risks such as emergent behaviour,
          misalignment with organisational goals, and difficulties in verification. Peer feedback challenged my
          initial optimism and prompted deeper consideration of governance, formal verification, and human oversight
          as essential design components rather than optional safeguards.
        </p>

        <p>
          During Discussion 2, my understanding of agent communication evolved substantially. Comparing ACLs with
          traditional method invocation made clear that knowledge-level communication enables autonomy and negotiation
          but introduces semantic ambiguity and computational overhead. This tension between flexibility and
          predictability reinforced the idea that architectural choices must be driven by context rather than
          technical preference alone. I found peer exchanges particularly valuable in clarifying how shared ontologies
          and protocol design reduce communication failure in open systems.
        </p>

        <p>
          Discussion 3 had the strongest personal impact. Examining ethical risks associated with generative and
          learning-enabled agents raised concerns about bias amplification, misinformation, intellectual property,
          and accountability. I experienced a shift from viewing ethics as a compliance requirement to recognising it
          as a core engineering responsibility. The idea that harm can be predictable and measurable changed how I
          evaluate “success” in AI systems, moving beyond accuracy to fairness, transparency, and trust.
        </p>

        <p>
          Emotionally, the module required sustained critical engagement. Responding to peers exposed gaps in my own
          assumptions and required me to defend, revise, or abandon positions based on evidence. While challenging,
          this process strengthened my confidence in academic debate and improved my ability to integrate diverse
          viewpoints into coherent arguments.
        </p>
      </div>

      <div class="card prose">
        <h3>Now What? — Application and future development</h3>

        <p>
          The learning from this module directly informs how I will approach the design and evaluation of intelligent
          systems in future academic and professional contexts. I now assess agent-based solutions not only on
          technical feasibility but also on governance readiness, ethical risk, and organisational fit.
        </p>

        <p>
          Practically, I will apply structured evaluation methods when working with intelligent or autonomous systems,
          including defining appropriate performance metrics, measuring variance and uncertainty, and identifying
          conditions that require human escalation. I will also prioritise transparent documentation and auditability,
          particularly when systems operate in sensitive or safety-critical environments.
        </p>

        <p>
          From a professional development perspective, the module strengthened key skills including critical
          analysis, academic communication, collaborative working, and ethical reasoning. These skills are directly
          transferable to multidisciplinary teams where technical decisions have legal, social, and operational
          consequences.
        </p>

        <p>
          Finally, this module has shaped my long-term academic direction. It reinforced my interest in intelligent
          systems that interact with humans and institutions, and in research that balances innovation with
          responsibility. As I progress through the MSc programme, I will continue to integrate agent-based thinking
          with data-driven methods, always considering how design choices influence real-world outcomes.
        </p>
      </div>

      <div class="card prose">
        <h3>Conclusion</h3>
        <p>
          Overall, the Intelligent Agents module provided a comprehensive and challenging learning experience.
          Through reflective practice, peer engagement, and critical analysis, I developed a more mature and
          responsible understanding of intelligent agent systems. The module emphasised that effective agent design
          is not solely about autonomy or performance, but about building systems that can be trusted, governed, and
          aligned with human values.
        </p>
      </div>

      <div class="card prose refs">
        <h3>References</h3>
        <ul>
          <li>Rolfe, G., Freshwater, D. and Jasper, M. (2001) <em>Critical Reflection in Nursing and the Helping Professions</em>. Basingstoke: Palgrave Macmillan.</li>
          <li>Russell, S. and Norvig, P. (2021) <em>Artificial Intelligence: A Modern Approach</em>. 4th edn. Harlow: Pearson.</li>
          <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
          <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence</em>. Cham: Springer.</li>
          <li>Floridi, L. et al. (2018) ‘AI4People—An ethical framework for a good AI society’, <em>Minds and Machines</em>, 28(4), pp. 689–707.</li>
          <li>Jobin, A., Ienca, M. and Vayena, E. (2019) ‘The global landscape of AI ethics guidelines’, <em>Nature Machine Intelligence</em>, 1(9), pp. 389–399.</li>
        </ul>
      </div>

    </section>

    <footer class="footer">
      <span>© Naeema Alnaqbi • Intelligent Agents e-Portfolio</span>
      <a class="toplink" href="#top">Back to top</a>
    </footer>

  </main>
</body>
</html>

