<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Agent-Based Systems – Intelligent Agents e-Portfolio</title>
</head>
<body>

<h1>Intelligent Agents</h1>
<h2>MSc Artificial Intelligence – e-Portfolio</h2>

<ul>
  <li><a href="index.html">Home</a></li>
  <li><a href="discussions.html">Discussions</a></li>
  <li><a href="agent-based-systems.html">Agent-Based Systems</a></li>
  <li><a href="agent-communication.html">Agent Communication</a></li>
  <li><a href="deep-learning.html">Deep Learning</a></li>
  <li><a href="activities.html">Activities</a></li>
  <li><a href="about.html">About</a></li>
</ul>

<hr>

<h2 id="cd1">Collaborative Discussion 1: Agent-Based Systems (Units 1–3)</h2>
<p>Exploring the rise, benefits, risks and governance of agent-based systems in modern organisations.</p>

<p><a href="#top">↑ Back to top</a></p>

<!-- OPTIONAL DIAGRAM FOR E-PORTFOLIO BONUS -->
<h3>Concept Figure – Agent-Based System in an Organisation</h3>
<p><em>(In the GitHub version, you can replace this text with an embedded diagram image,
for example <code>&lt;img src="images/abs-diagram.png" alt="High-level agent-based system overview"&gt;</code>.)</em></p>

<hr>

<h3 id="initial-post">Initial Post</h3>
<h4>The Rise and Benefits of Agent-Based Systems in Modern Organisations</h4>

<p>
The rise of agent-based systems (ABS) reflects a shift from centralised architectures toward decentralised,
adaptive intelligence that can cope with the complexity of modern organisations. Traditional systems
struggle when environments are distributed, dynamic and heterogeneous, whereas ABS model such settings as
collections of autonomous agents that perceive, reason and act locally while still contributing to global
organisational goals (Wooldridge and Jennings, 1995; Wooldridge, 2021). Advances in artificial intelligence,
especially in knowledge representation and learning, combined with the growth of distributed computing, have
made these systems feasible at scale (Russell and Norvig, 2021; Macal and North, 2010).
</p>

<p>
From a technical perspective, several agent models support different organisational needs. Logic-based
Belief–Desire–Intention (BDI) agents link first-order logic and practical reasoning to operational
decision-making in complex domains (Rao and Georgeff, 1995). Behaviour-based agents, inspired by Brooks’
“intelligence without representation”, provide fast, reactive control in robotics and embedded systems
(Brooks, 1991). Modern hybrid architectures combine deliberative and reactive layers, while multi-agent
reinforcement learning extends agents with adaptive behaviour in cooperative and competitive environments
(Lowe et al., 2017; Winikoff, 2017).
</p>

<p>
The organisational benefits of ABS are visible in several real-world systems. In manufacturing, DaimlerChrysler’s
agent-based control improved robustness and flexibility on production lines operating under uncertainty
(Jennings and Bussmann, 2003). In logistics, Kiva Systems (now Amazon Robotics) used hundreds of warehouse robots
coordinated through an agent-based approach to double picker productivity and increase throughput
(Wurman, D’Andrea and Mountz, 2008). At infrastructure level, the JADE framework provides a FIPA-compliant
platform that allows organisations to deploy interoperable agents for coordination, negotiation and distributed
control (Bellifemine, Caire and Greenwood, 2007). Recent multi-agent reinforcement learning work, such as
DeepMind-style actor–critic methods, demonstrates how agents can jointly learn strategies for complex tasks,
pointing to future applications in markets, traffic and resource allocation (Lowe et al., 2017).
</p>

<p>
However, these benefits come with non-trivial risks. Autonomous agents can produce emergent behaviours that conflict
with organisational policies or legal requirements if they are not properly governed (Dignum, 2019; Rahwan, 2018).
In data-driven agents, privacy and compliance with frameworks such as the EU General Data Protection Regulation (GDPR)
must be considered when agents share or process personal data across distributed environments
(Voigt and Von dem Bussche, 2017). This makes accountability, formal verification and transparent decision-making
essential (Fisher et al., 2021; Raji, Smart and White, 2020).
</p>

<p>
Overall, agent-based systems are well aligned with organisations that operate in distributed, uncertain and
fast-changing contexts. When combined with clear governance, human oversight and legal safeguards, they offer
a powerful way to scale decision-making, improve resilience and manage complexity.
</p>

<h4>References</h4>
<ul>
  <li>Bellifemine, F., Caire, G. and Greenwood, D. (2007) <em>Developing Multi-Agent Systems with JADE</em>. Chichester: John Wiley &amp; Sons.</li>
  <li>Brooks, R.A. (1991) ‘Intelligence without representation’, <em>Artificial Intelligence</em>, 47(1–3), pp. 139–159.</li>
  <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way</em>. Cham: Springer.</li>
  <li>Fisher, M. et al. (2021) ‘Towards a framework for certification of reliable autonomous systems’, <em>Autonomous Agents and Multi-Agent Systems</em>, 35(1), pp. 1–65.</li>
  <li>Jennings, N.R. and Bussmann, S. (2003) ‘Agent-based control systems: Why are they suited to engineering complex systems?’, <em>IEEE Control Systems Magazine</em>, 23(3), pp. 61–73.</li>
  <li>Lowe, R. et al. (2017) ‘Multi-agent actor-critic for mixed cooperative–competitive environments’, in <em>Proceedings of the 31st International Conference on Neural Information Processing Systems (NeurIPS 2017)</em>, pp. 6379–6390.</li>
  <li>Macal, C.M. and North, M.J. (2010) ‘Tutorial on agent-based modelling and simulation’, <em>Journal of Simulation</em>, 4(3), pp. 151–162.</li>
  <li>Raji, I.D., Smart, A. and White, R.N. (2020) ‘Closing the AI accountability gap’, in <em>Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT 2020)</em>, pp. 336–345.</li>
  <li>Rao, A.S. and Georgeff, M.P. (1995) ‘BDI agents: From theory to practice’, in <em>Proceedings of the First International Conference on Multi-Agent Systems (ICMAS 1995)</em>, pp. 312–319.</li>
  <li>Rahwan, I. (2018) ‘Society-in-the-loop: Programming the algorithmic social contract’, <em>Ethics and Information Technology</em>, 20(1), pp. 5–14.</li>
  <li>Russell, S. and Norvig, P. (2021) <em>Artificial Intelligence: A Modern Approach</em>. 4th edn. Harlow: Pearson.</li>
  <li>Voigt, P. and Von dem Bussche, A. (2017) <em>The EU General Data Protection Regulation (GDPR): A Practical Guide</em>. Cham: Springer.</li>
  <li>Winikoff, M. (2017) ‘Challenges and directions for engineering multi-agent systems’, <em>Autonomous Agents and Multi-Agent Systems</em>, 31(4), pp. 779–817.</li>
  <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
  <li>Wooldridge, M. and Jennings, N.R. (1995) ‘Intelligent agents: Theory and practice’, <em>The Knowledge Engineering Review</em>, 10(2), pp. 115–152.</li>
  <li>Wurman, P.R., D’Andrea, R. and Mountz, M. (2008) ‘Coordinating hundreds of cooperative robots for warehouse automation’, <em>AI Magazine</em>, 29(1), pp. 9–19.</li>
</ul>

<p><a href="#top">↑ Back to top</a></p>

<hr>

<h3 id="peer-ariel">Peer Response to Ariel Mella</h3>

<p>
Hi Ariel,
</p>

<p>
Your post offers a rich, historically grounded view of how agent-based systems (ABS) emerged from centralised
ERP-style architectures to today’s microservices, cloud and service-oriented designs. I especially liked how you
connected FIPA-compliant platforms with concrete industrial cases such as DaimlerChrysler, Kiva and Alibaba,
which clearly demonstrate that ABS deliver measurable value rather than remaining only theoretical
(Bellifemine, Poggi and Rimassa, 2001; Jennings and Bussmann, 2003; Wurman, D’Andrea and Mountz, 2008).
</p>

<p>
I agree with your emphasis on scalability and resilience, but I see your examples also highlighting a second
layer of value: learning and coordination under uncertainty. Your reference to MADDPG aligns well with current
work in multi-agent reinforcement learning, where centralised training with decentralised execution helps agents
learn stable joint policies in non-stationary environments (Lowe et al., 2017). This addresses some of the
“credit assignment” and coordination problems you mentioned, and connects directly to industrial settings such as
traffic optimisation, RTB markets and large-scale logistics (Foerster et al., 2018).
</p>

<p>
At the same time, your discussion of technical debt and process misalignment is crucial. As you note with
Sculley et al. (2015), simply “dropping in” learning agents into legacy workflows can create fragile systems that
are hard to monitor and debug. Dignum (2019) and Rahwan (2018) argue that such systems require explicit governance
frameworks that make responsibilities, oversight and escalation paths clear. I would add that, when ABS operate on
personal or behavioural data—as in marketing and personalised recommender settings—they must also comply with privacy
and data-protection requirements such as GDPR, which constrain how agents log, share and retain information
(Voigt and Von dem Bussche, 2017).
</p>

<p>
Overall, your post helped me see ABS less as isolated technical components and more as socio-technical systems
that interact with processes, regulations and organisational culture. Your combination of architectures,
real-world case studies and critical reflection on risk provides an excellent foundation for thinking about how
organisations should adopt ABS responsibly.
</p>

<h4>References</h4>
<ul>
  <li>Bellifemine, F., Poggi, A. and Rimassa, G. (2001) ‘Developing multi agent systems with a FIPA compliant agent framework’, <em>Software: Practice and Experience</em>, 31(2), pp. 103–128.</li>
  <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way</em>. Cham: Springer.</li>
  <li>Foerster, J.N. et al. (2018) ‘Counterfactual multi-agent policy gradients’, in <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 32(1).</li>
  <li>Jennings, N.R. and Bussmann, S. (2003) ‘Agent-based control systems: Why are they suited to engineering complex systems?’, <em>IEEE Control Systems Magazine</em>, 23(3), pp. 61–73.</li>
  <li>Lowe, R. et al. (2017) ‘Multi-agent actor-critic for mixed cooperative–competitive environments’, in <em>Proceedings of the 31st International Conference on Neural Information Processing Systems (NeurIPS 2017)</em>, pp. 6379–6390.</li>
  <li>Rahwan, I. (2018) ‘Society-in-the-loop: Programming the algorithmic social contract’, <em>Ethics and Information Technology</em>, 20(1), pp. 5–14.</li>
  <li>Sculley, D. et al. (2015) ‘Hidden technical debt in machine learning systems’, in <em>Advances in Neural Information Processing Systems (NeurIPS 2015)</em>, 28, pp. 2503–2511.</li>
  <li>Voigt, P. and Von dem Bussche, A. (2017) <em>The EU General Data Protection Regulation (GDPR): A Practical Guide</em>. Cham: Springer.</li>
  <li>Wurman, P.R., D’Andrea, R. and Mountz, M. (2008) ‘Coordinating hundreds of cooperative robots for warehouse automation’, <em>AI Magazine</em>, 29(1), pp. 9–19.</li>
</ul>

<p><a href="#top">↑ Back to top</a></p>

<hr>

<h3 id="peer-bashair">Peer Response to Bashair Alhosani</h3>

<p>
Hi Bashair,
</p>

<p>
Your post gives a clear and well-structured explanation of how agent-based systems (ABS) emerged from the
limitations of centralised architectures and why they are attractive for modern organisations. I particularly
appreciated your use of the BDI model and the way you linked it back to AI foundations, showing how beliefs,
desires and intentions provide a bridge between logical reasoning and practical decision-making
(Rao and Georgeff, 1995; Russell and Norvig, 2021).
</p>

<p>
Building on your discussion of modularity and real-time responsiveness, I think your examples naturally point
towards governance and verification as key success factors. As you suggested, the same flexibility that allows
agents to adapt locally can introduce risks of misalignment or unexpected emergent behaviour. Winikoff (2017)
and Fisher et al. (2021) argue that formal verification and certification frameworks are increasingly necessary,
especially when ABS support safety-critical or high-impact decisions. These ideas connect strongly with your
point about aligning agent behaviour with organisational policies.
</p>

<p>
I also found your reference to hybrid architectures very relevant. In practice, many large-scale systems combine
reactive agents for low-latency responses with deliberative or learning-based components for higher-level
planning (Wooldridge, 2021; Bellifemine, Caire and Greenwood, 2007). Kiva’s warehouse robots and similar systems
show how this layered approach can deliver both robustness and adaptability in real deployments
(Wurman, D’Andrea and Mountz, 2008).
</p>

<p>
Finally, I appreciate that you acknowledged ethical and security concerns. When agents operate on distributed
organisational data—especially personal or sensitive information—legal frameworks such as GDPR impose constraints
on how data can be processed, logged and shared (Voigt and Von dem Bussche, 2017). Dignum (2019) and Rahwan (2018)
emphasise that ABS should therefore be embedded within broader responsible-AI and “society-in-the-loop” governance
structures. Your argument about balancing autonomy with control fits very well within this perspective.
</p>

<p>
Overall, your post provides a strong foundation that connects theory, architecture and organisational practice.
By bringing in verification, governance and legal considerations, it becomes a very complete view of what it
takes to deploy ABS safely and effectively.
</p>

<h4>References</h4>
<ul>
  <li>Bellifemine, F., Caire, G. and Greenwood, D. (2007) <em>Developing Multi-Agent Systems with JADE</em>. Chichester: John Wiley &amp; Sons.</li>
  <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way</em>. Cham: Springer.</li>
  <li>Fisher, M. et al. (2021) ‘Towards a framework for certification of reliable autonomous systems’, <em>Autonomous Agents and Multi-Agent Systems</em>, 35(1), pp. 1–65.</li>
  <li>Rao, A.S. and Georgeff, M.P. (1995) ‘BDI agents: From theory to practice’, in <em>Proceedings of the First International Conference on Multi-Agent Systems (ICMAS 1995)</em>, pp. 312–319.</li>
  <li>Rahwan, I. (2018) ‘Society-in-the-loop: Programming the algorithmic social contract’, <em>Ethics and Information Technology</em>, 20(1), pp. 5–14.</li>
  <li>Russell, S. and Norvig, P. (2021) <em>Artificial Intelligence: A Modern Approach</em>. 4th edn. Harlow: Pearson.</li>
  <li>Voigt, P. and Von dem Bussche, A. (2017) <em>The EU General Data Protection Regulation (GDPR): A Practical Guide</em>. Cham: Springer.</li>
  <li>Winikoff, M. (2017) ‘Challenges and directions for engineering multi-agent systems’, <em>Autonomous Agents and Multi-Agent Systems</em>, 31(4), pp. 779–817.</li>
  <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
  <li>Wurman, P.R., D’Andrea, R. and Mountz, M. (2008) ‘Coordinating hundreds of cooperative robots for warehouse automation’, <em>AI Magazine</em>, 29(1), pp. 9–19.</li>
</ul>

<p><a href="#top">↑ Back to top</a></p>

<hr>

<h3 id="summary">Summary Post</h3>
<h4>Agent-Based Systems and Decentralised Intelligence</h4>

<p>
Across this discussion, my understanding of agent-based systems (ABS) has evolved from seeing them as a technical
alternative to centralised architectures to recognising them as a broader socio-technical approach to managing
complexity. The units introduced core concepts such as intelligent agents, first-order logic and agent architectures,
while peers’ posts illustrated how these ideas translate into real systems in logistics, healthcare, finance and
manufacturing (Wooldridge and Jennings, 1995; Macal and North, 2010; Wooldridge, 2021).
</p>

<p>
A consistent theme was that ABS are well suited to complex, distributed and dynamic environments. From a modelling
perspective, agent-based simulation allows organisations to explore “what-if” scenarios and emergent behaviour before
changing real operations (Macal and North, 2010). Operationally, examples such as DaimlerChrysler’s production lines
and Kiva’s warehouse robots show that distributed agents can increase robustness, throughput and adaptability compared
to rigid centralised control (Jennings and Bussmann, 2003; Wurman, D’Andrea and Mountz, 2008). Frameworks like JADE
and FIPA standards provide practical infrastructure for building interoperable multi-agent platforms across heterogeneous
systems (Bellifemine, Poggi and Rimassa, 2001; Bellifemine, Caire and Greenwood, 2007).
</p>

<p>
The course content on BDI, reactive and hybrid architectures helped me understand how agents link knowledge,
reasoning and action. BDI agents implement the Belief–Desire–Intention model derived from practical reasoning,
while behaviour-based agents provide fast responses in dynamic environments (Rao and Georgeff, 1995; Brooks, 1991;
Russell and Norvig, 2021). Peers extended this by highlighting multi-agent reinforcement learning methods such as
MADDPG, where agents learn coordinated policies under centralised training but act decentrally at run time
(Lowe et al., 2017; Foerster et al., 2018).
</p>

<p>
However, peer responses also shifted the discussion from benefits to risks and governance. Contributors emphasised
that autonomy and emergence can lead to incidents such as flash crashes, unfair decisions or misaligned incentives if
agent goals diverge from organisational or societal objectives (Dignum, 2019; Rahwan, 2018). This aligns with work on
responsible AI and “society-in-the-loop”, which argues for explicit oversight, auditability and alignment mechanisms
for autonomous systems (Raji, Smart and White, 2020). Formal verification and certification frameworks were discussed
as ways to bound behaviour and increase trust, particularly in safety-critical contexts (Fisher et al., 2021;
Winikoff, 2017).
</p>

<p>
An additional dimension is the legal and ethical context. Many real-world ABS operate on personal, behavioural or
transactional data. In such cases, regulations like the EU GDPR impose requirements on data minimisation,
transparency and accountability, which must be reflected in agent design, logging and communication
(Voigt and Von dem Bussche, 2017). This reinforced my view that deploying ABS is not only a system-design decision
but also a governance and compliance challenge.
</p>

<p>
Overall, the discussion helped me integrate theory, applications and critical reflection. Agent-based systems appear
most valuable when organisations combine decentralised decision-making with: (1) explicit representations of goals and
knowledge, (2) redesigned processes that account for autonomy, (3) human-in-the-loop oversight and (4) strong legal,
ethical and verification frameworks. When these elements are present, ABS provide a powerful, future-oriented approach
for operating in complex digital environments.
</p>

<h4>References</h4>
<ul>
  <li>Bellifemine, F., Caire, G. and Greenwood, D. (2007) <em>Developing Multi-Agent Systems with JADE</em>. Chichester: John Wiley &amp; Sons.</li>
  <li>Bellifemine, F., Poggi, A. and Rimassa, G. (2001) ‘Developing multi agent systems with a FIPA compliant agent framework’, <em>Software: Practice and Experience</em>, 31(2), pp. 103–128.</li>
  <li>Brooks, R.A. (1991) ‘Intelligence without representation’, <em>Artificial Intelligence</em>, 47(1–3), pp. 139–159.</li>
  <li>Dignum, V. (2019) <em>Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way</em>. Cham: Springer.</li>
  <li>Fisher, M. et al. (2021) ‘Towards a framework for certification of reliable autonomous systems’, <em>Autonomous Agents and Multi-Agent Systems</em>, 35(1), pp. 1–65.</li>
  <li>Foerster, J.N. et al. (2018) ‘Counterfactual multi-agent policy gradients’, in <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 32(1).</li>
  <li>Jennings, N.R. and Bussmann, S. (2003) ‘Agent-based control systems: Why are they suited to engineering complex systems?’, <em>IEEE Control Systems Magazine</em>, 23(3), pp. 61–73.</li>
  <li>Lowe, R. et al. (2017) ‘Multi-agent actor-critic for mixed cooperative–competitive environments’, in <em>Proceedings of the 31st International Conference on Neural Information Processing Systems (NeurIPS 2017)</em>, pp. 6379–6390.</li>
  <li>Macal, C.M. and North, M.J. (2010) ‘Tutorial on agent-based modelling and simulation’, <em>Journal of Simulation</em>, 4(3), pp. 151–162.</li>
  <li>Raji, I.D., Smart, A. and White, R.N. (2020) ‘Closing the AI accountability gap’, in <em>Proceedings of the Conference on Fairness, Accountability, and Transparency (FAccT 2020)</em>, pp. 336–345.</li>
  <li>Rao, A.S. and Georgeff, M.P. (1995) ‘BDI agents: From theory to practice’, in <em>Proceedings of the First International Conference on Multi-Agent Systems (ICMAS 1995)</em>, pp. 312–319.</li>
  <li>Rahwan, I. (2018) ‘Society-in-the-loop: Programming the algorithmic social contract’, <em>Ethics and Information Technology</em>, 20(1), pp. 5–14.</li>
  <li>Russell, S. and Norvig, P. (2021) <em>Artificial Intelligence: A Modern Approach</em>. 4th edn. Harlow: Pearson.</li>
  <li>Voigt, P. and Von dem Bussche, A. (2017) <em>The EU General Data Protection Regulation (GDPR): A Practical Guide</em>. Cham: Springer.</li>
  <li>Winikoff, M. (2017) ‘Challenges and directions for engineering multi-agent systems’, <em>Autonomous Agents and Multi-Agent Systems</em>, 31(4), pp. 779–817.</li>
  <li>Wooldridge, M. (2021) <em>An Introduction to MultiAgent Systems</em>. 2nd edn. Chichester: John Wiley &amp; Sons.</li>
  <li>Wooldridge, M. and Jennings, N.R. (1995) ‘Intelligent agents: Theory and practice’, <em>The Knowledge Engineering Review</em>, 10(2), pp. 115–152.</li>
  <li>Wurman, P.R., D’Andrea, R. and Mountz, M. (2008) ‘Coordinating hundreds of cooperative robots for warehouse automation’, <em>AI Magazine</em>, 29(1), pp. 9–19.</li>
</ul>

<p><a href="#top">↑ Back to top</a></p>

<hr>

<h3>Quick navigation</h3>
<ul>
  <li><a href="#initial-post">Initial Post</a></li>
  <li><a href="#peer-ariel">Peer Response – Ariel</a></li>
  <li><a href="#peer-bashair">Peer Response – Bashair</a></li>
  <li><a href="#summary">Summary Post</a></li>
</ul>

<p>
Agent-Based Systems · Intelligent Agents – e-Portfolio · Naeema Abdalla Ahmed Alnaqbi
</p>

</body>
</html>
